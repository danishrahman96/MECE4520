{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORTDa38wTgZ4iufY8eWhv6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danishrahman96/MECE4520/blob/main/Data_Science_HW_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4HsMJCljk_K"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"https://raw.githubusercontent.com/changyaochen/MECE4520/master/data/simple_linear_regression.csv\",names=[\"x\",\"y\"])\n",
        "x = data[\"x\"]\n",
        "y = data[\"y\"]"
      ],
      "metadata": {
        "id": "A6_JyDwWjxh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem 1: Part 1\n",
        "\n",
        "The loss function will be the mean sum of squared errors (MSE). \n",
        "\n",
        "\\begin{align*}\n",
        "  MSE =  \\frac{1}{N}\\sum_{i=1}^{N} (Y_i-\\hat{Y_i})^2\n",
        "\\end{align*}"
      ],
      "metadata": {
        "id": "KVbgBOj8FA4w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem #1: Part 2"
      ],
      "metadata": {
        "id": "ydUEAsQIe3eg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gradient function for the loss function is as below:\n",
        "\n",
        "\\begin{align*}\n",
        "\\frac{\\partial f}{\\partial \\beta_1} = \\frac{1}{N}\\sum_{i=1}^{N} -2x_i(y_i-(\\beta_0+\\beta_1x_i))^2\n",
        "\\end{align*}\n",
        "\n",
        "\\begin{align*}\n",
        "\\frac{\\partial f}{\\partial \\beta_0} = \\frac{1}{N}\\sum_{i=1}^{N} -2(y_i-(\\beta_0+\\beta_1x_i))^2\n",
        "\\end{align*}"
      ],
      "metadata": {
        "id": "MM2jV5hklQQh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Problem #1: Part 3"
      ],
      "metadata": {
        "id": "wFHLw2XjiNGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_regression_loss(x,y,betas):\n",
        "   \n",
        "    y_pred = x @ betas\n",
        "    loss = 1/len(data)*np.sum(np.square(y - x @ betas))\n",
        "        \n",
        "    return loss"
      ],
      "metadata": {
        "id": "J_Zck2P4GeEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = np.vstack((np.ones(shape=len(data)), data['x'].values.T)).T\n",
        "y1 = data[\"y\"].values\n",
        "auto_betas = [1, 1]\n",
        "linear_regression_loss(x=x1, y=y1, betas=auto_betas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFh26XYWGhfG",
        "outputId": "a156dc99-6e51-4a79-9460-80a14bbefe2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38043.91740195"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Problem #1: Part 4"
      ],
      "metadata": {
        "id": "XeHomSwqilOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient Function\n",
        "\n",
        "def linear_regression_loss_gradient(x,y,betas):\n",
        "    grad = (1/len(x1))*-2*(x.T @ (y - x @ betas))\n",
        "    \n",
        "    return grad"
      ],
      "metadata": {
        "id": "b8orKlUUilAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.001\n",
        "beta_0 = 1;beta_1 = 1;\n",
        "betas = np.array([beta_0,beta_1]).T\n",
        "guess_cur = betas\n",
        "for j in range(10):\n",
        "  guess_next = guess_cur - alpha * linear_regression_loss_gradient(x=x1, y=y1, betas=guess_cur)\n",
        "  guess_cur = guess_next\n",
        "\n",
        "print(\"The final values for Beta_0 and Beta_1 are:\")\n",
        "print(guess_next)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbc_NPP4K-m9",
        "outputId": "68793d62-a7af-4a5c-b781-8eea073f9b22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The final values for Beta_0 and Beta_1 are:\n",
            "[ 0.65964979 16.00762665]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem 2: Part 1"
      ],
      "metadata": {
        "id": "c4JQK4n441LC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"https://raw.githubusercontent.com/changyaochen/MECE4520/master/data/logistic_regression.csv\",names=[\"x1\",\"x2\",\"y\"])\n",
        "x1 = data[\"x1\"]\n",
        "x2 = data[\"x2\"]\n",
        "y2 = data[\"y\"]"
      ],
      "metadata": {
        "id": "SnNyTeqC43T2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The loss function will be the cross-entropy. \n",
        "\n",
        "\\begin{align*}\n",
        "  \\mathcal{L}(\\beta) = -\\frac{1}{N}\\sum_{i=1}^{n}(y_i\\ln(\\sigma(z_i)) + (1-y_i)\\ln(1-\\sigma(z_i))) \n",
        "\\end{align*}"
      ],
      "metadata": {
        "id": "xbQM5Xrv5bgM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem 2: Part 2\n",
        "\n",
        "The gradient function for the logloss function is as below. \n",
        "\n",
        "\\begin{align*}\n",
        "\\frac{\\partial \\mathcal{L}(\\beta)}{\\partial \\beta_j} = -\\frac{1}{N}\\sum_{i=1}^{n} ((y_i-\\sigma(z_i))\\frac{\\partial z}{\\partial \\beta_j}\n",
        "\\end{align*}"
      ],
      "metadata": {
        "id": "dc8l8y756nMn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem 2: Part 3"
      ],
      "metadata": {
        "id": "3fwMwdDblsLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z_i):\n",
        "    return 1 / (1 + np.exp(-z_i))\n",
        "\n",
        "def log_regr_loss(y_2,z_i):\n",
        "    loss = -1/len(y_2)*np.sum(y_2 * np.log(1e-10 + sigmoid(z_i))+(1 - y_2)*np.log(1e-10 + 1 - sigmoid(z_i)))\n",
        "    return loss"
      ],
      "metadata": {
        "id": "9zIxWx6kTmv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beta_0 = 5;beta_1 = -5;beta_2 = 5\n",
        "betas = np.array([beta_0,beta_1,beta_2]).T\n",
        "z_i = beta_0+beta_1*x1+beta_2*x2\n",
        "log_regr = log_regr_loss(y_2 = y2,z_i=z_i)\n",
        "print(f\"The value of the logloss function is:{log_regr: 5.5f}\")"
      ],
      "metadata": {
        "id": "F414TTI_l1-p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e83c558-3c6f-48f2-cbf1-8c7ec4d7dc23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The value of the logloss function is: 0.05094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem 2: Part 4"
      ],
      "metadata": {
        "id": "mjQjtJ_Yxa_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_regression_loss_gradient(X,y,betas):\n",
        "    if not isinstance(betas, np.ndarray):\n",
        "        betas = np.array(betas).reshape(-1, 1)\n",
        "    if y.ndim == 1:\n",
        "        y = y.reshape(-1, 1)\n",
        "    \n",
        "    grad = (1/len(X))*-1. * (X.T @ (y - sigmoid(X @ betas)))  \n",
        "    return grad"
      ],
      "metadata": {
        "id": "zTuVwM9ixhSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_2 = np.vstack((np.ones(shape=len(data)), data[['x1','x2']].values.T)).T\n",
        "y2 = data[\"y\"].values\n",
        "alpha = 1\n",
        "beta_0 = 5;beta_1 = -5;beta_2 = 5\n",
        "betas = np.array([[beta_0],[beta_1],[beta_2]])\n",
        "guess_cur = betas\n",
        "\n",
        "for i in range(2000):\n",
        "  guess_next = guess_cur - alpha * logistic_regression_loss_gradient(X=x_2,y=y2,betas=guess_cur)\n",
        "  guess_cur = guess_next\n",
        "\n",
        "print(\"The final values for Beta_0, Beta_1 and Beta_2 are:\")\n",
        "print(guess_next)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o250flVO10ob",
        "outputId": "63cd031f-d68b-4319-a3e6-c455682adaf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The final values for Beta_0, Beta_1 and Beta_2 are:\n",
            "[[ 4.845585  ]\n",
            " [-6.61722405]\n",
            " [ 8.23475816]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "jupyter nbconvert --to html /Data_Science_HW_3.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7u9q5-iNOm8",
        "outputId": "0d57d4ea-a542-4fa8-ecd0-64e33ef594b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook /Data_Science_HW_3.ipynb to html\n",
            "[NbConvertApp] Writing 295453 bytes to /Data_Science_HW_3.html\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    }
  ]
}